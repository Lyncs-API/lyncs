{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to dask-mpi\n",
    "\n",
    "Before proceeding to this notebook, we suggest the reading of [\"Introduction to dask\"](Dask.ipynb)\n",
    "\n",
    "## Initialization\n",
    "### Interactive jobs\n",
    "\n",
    "When dask is used interactively (e.g. like here in a notebook), dask-mpi needs to be run in the background as a server with a command of the kind\n",
    "```bash\n",
    "mpirun -n $((N+1)) dask-mpi --no-nanny --scheduler-file scheduler.json --nthreads 1\n",
    "```\n",
    "where `N+1` is the total number of processes having one scheduler and N workers.\n",
    "\n",
    "Then in the notebook we connect to the server by doing\n",
    "```python\n",
    "from dask.distributed import Client\n",
    "client = Client(scheduler_file=\"scheduler.json\")\n",
    "```\n",
    "\n",
    "### Batch jobs\n",
    "\n",
    "When dask is used in a script, the script needs to be executed in parallel with a command of the kind\n",
    "```bash\n",
    "mpirun -n $((N+1)) python script.py\n",
    "```\n",
    "and the first line of script.py should be\n",
    "```python\n",
    "from dask_mpi import initialize\n",
    "initialize(nthreads=1, nanny=False)\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "```\n",
    "\n",
    "For more details about dask-mpi refer to its [documentation](https://mpi.dask.org/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "In the following we start start the server and connect to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh\n",
    "import tempfile\n",
    "\n",
    "# Since dask-mpi produces several file we create a temporary directory\n",
    "tmppath = tempfile.mkdtemp()\n",
    "sh.cd(tmppath)\n",
    "\n",
    "# Here we set the number of workers\n",
    "workers = 8\n",
    "threads_per_worker = 1\n",
    "\n",
    "# The command runs in the background (_bg=True) and the stdout(err) is stored in tmppath+\"/log.out(err)\"\n",
    "server = sh.mpirun(\"-n\", workers+1, \"dask-mpi\", \"--no-nanny\", \"--nthreads\", threads_per_worker,\n",
    "          \"--scheduler-file\", \"scheduler.json\", _bg = True, _out=\"log.out\", _err=\"log.err\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.20.110.9:46756</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.20.110.9:8787/status' target='_blank'>http://10.20.110.9:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>33.67 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.20.110.9:46756' processes=8 threads=8, memory=33.67 GB>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(scheduler_file=tmppath+\"/scheduler.json\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workers\n",
    "\n",
    "Information about the workers can be get using\n",
    "```python\n",
    "client.scheduler_info()[\"workers\"]\n",
    "```\n",
    "that returns a dictionary with keys the workers name and content the last update about the worker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tcp://10.20.110.9:33646',\n",
       " 'tcp://10.20.110.9:34231',\n",
       " 'tcp://10.20.110.9:34565',\n",
       " 'tcp://10.20.110.9:37555',\n",
       " 'tcp://10.20.110.9:38215',\n",
       " 'tcp://10.20.110.9:38225',\n",
       " 'tcp://10.20.110.9:40114',\n",
       " 'tcp://10.20.110.9:44958']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers = list(client.scheduler_info()[\"workers\"].keys())\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Worker',\n",
       " 'id': 3,\n",
       " 'host': '10.20.110.9',\n",
       " 'resources': {},\n",
       " 'local_directory': '/tmp/tmp51a9u_o8/worker-lv7zrwwr',\n",
       " 'name': 3,\n",
       " 'nthreads': 1,\n",
       " 'memory_limit': 4208159232,\n",
       " 'last_seen': 1579600151.471659,\n",
       " 'services': {},\n",
       " 'metrics': {'cpu': 2.0,\n",
       "  'memory': 37462016,\n",
       "  'time': 1579600151.4707541,\n",
       "  'read_bytes': 11126.181017576566,\n",
       "  'write_bytes': 11126.181017576566,\n",
       "  'num_fds': 30,\n",
       "  'executing': 0,\n",
       "  'in_memory': 0,\n",
       "  'ready': 0,\n",
       "  'in_flight': 0,\n",
       "  'bandwidth': {'total': 100000000, 'workers': {}, 'types': {}}},\n",
       " 'nanny': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The known information are for example\n",
    "client.scheduler_info()[\"workers\"][workers[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed operations\n",
    "We can initialize a group of workers for performing a task using the function \n",
    "```python\n",
    "client.scatter(list, workers = None or workers, broadcast=True)\n",
    "```\n",
    "where one of each element of the list will be given to one of the workers in a round-robin based. The list of workers can be selected between the workers available.\n",
    "\n",
    "The content of the list should contain information that the worker needs to proceed.\n",
    "\n",
    "Here a dummy example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: finished, type: int, key: int-5c8a950061aa331153f4a172bbcbfd1b>,\n",
       " <Future: status: finished, type: int, key: int-c0a8a20f903a4915b94db8de3ea63195>,\n",
       " <Future: status: finished, type: int, key: int-58e78e1b34eb49a68c65b54815d1b158>,\n",
       " <Future: status: finished, type: int, key: int-d3395e15f605bc35ab1bac6341a285e2>,\n",
       " <Future: status: finished, type: int, key: int-5cd9541ea58b401f115b751e79eabbff>,\n",
       " <Future: status: finished, type: int, key: int-ce9a05dd6ec76c6a6d171b0c055f3127>,\n",
       " <Future: status: finished, type: int, key: int-7ec5d3339274cee5cb507a4e4d28e791>,\n",
       " <Future: status: finished, type: int, key: int-06e5a71c9839bd98760be56f629b24cc>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = range(len(workers))\n",
    "group = client.scatter(dummy)\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[g.result() for g in group]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that they are actually distributed we get the rank of each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: get_rank-365664a3a51879f4972dfa0f25d10d4d>,\n",
       " <Future: status: pending, key: get_rank-8cf27643ff4fe6d33fab32af28ca3028>,\n",
       " <Future: status: pending, key: get_rank-cfedff0fe2e07c540be32d6a9f432aa5>,\n",
       " <Future: status: pending, key: get_rank-ebefe6f7e3178184c9c891ef1d5944b1>,\n",
       " <Future: status: pending, key: get_rank-6097bbfd21e515f4843d28ea4fe3a954>,\n",
       " <Future: status: pending, key: get_rank-323e5de00ac65950eacef2420da10580>,\n",
       " <Future: status: pending, key: get_rank-e83d33807ee8a903f9e068d55d6acab3>,\n",
       " <Future: status: pending, key: get_rank-e657977a6fd8541160567ecc93590a39>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rank(*args,comm=None):\n",
    "    if comm is None:\n",
    "        from mpi4py.MPI import COMM_WORLD as comm\n",
    "    return comm.rank\n",
    "\n",
    "ranks = client.map(get_rank, group)\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 8, 2, 7, 4, 1, 6, 3]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [rank.result() for rank in ranks]\n",
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that `rank = 0` is not in the list because indeed the scheduler is running on it and not a worker.\n",
    "\n",
    "Thus any MPI operation need to be run on a communcator involing only the workers and not the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comm(*args, ranks=None, comm=None):\n",
    "    assert ranks\n",
    "    if comm is None:\n",
    "        from mpi4py.MPI import COMM_WORLD as comm\n",
    "    return comm.Create_group(comm.group.Incl(ranks))\n",
    "\n",
    "comms = client.map(create_comm, group, workers=workers, ranks=ranks, actor=True)\n",
    "comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-0>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-1>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-2>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-3>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-4>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-5>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-6>,\n",
       " <Actor: Intracomm, key=create_comm-0bf3fd85-3aba-4187-9073-90bbd20c13b5-7>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comms = [comm.result() for comm in comms]\n",
    "comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 2, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[comm.rank for comm in comms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8, 8, 8, 8]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reductions = [comm.allreduce(1) for comm in comms]\n",
    "[r.result() for r in reductions]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
